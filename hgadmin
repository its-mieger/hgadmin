#! /usr/bin/env python

import ConfigParser, string, sys, os, re, subprocess, stat, shutil, base64, logging, logging.handlers
from mercurial import ui, hg, dispatch

try:
    request = dispatch.request
except AttributeError:
    request = list 

# directory where hgadmin searches for its configuration
BASEDIR='~/hgadmin-config'

def usage(name):
    x = """usage: 
{n} [-D] [--confdir DIR] maybe_create_repo USER PATH 
  creates repository at PATH, if USER is
  allowed. PATH is relative to configured repo directory.
{n} [-D] [--confdir DIR] create_repo PATH 
  creates repository at PATH. PATH is relative to configured repo directory.
{n} [-D] [--confdir DIR] updateauth
  updates authorization information in the managed repositories,
  regenerates authorized_keys file etc
{n} [-D] [--confdir DIR] verify
  reads in configuration and verifies its correctness (giving error messages)
{n} [-D] [--confdir DIR] accesscheck ACCESSTYPE USER PATH
  prints TRUE if access ACCESSTYPE on PATH is allowed to USER, else FALSE
{n} [-D] [--confdir DIR] getpattern PATH
  prints the pattern from the configuration that matches PATH
{n} [-D] [--confdir DIR] listusers
  lists all users
{n} [-D] [--confdir DIR] listgroups
  lists all groups
{n} [-D] [--confdir DIR] listusersingroup GROUP
  lists all users in group GROUP, if it exists
{n} [-D] [--confdir DIR] showunmanagedrepos
  prints a list of all unmanaged repositories
{n} [-D] [--confdir DIR] showrepos
  prints a list of all managed repositories
{n} [-D] [--confdir DIR] make_repo_managed REPO
  converts repository REPO to a managed repository.
The configuration directory defaults to "~/hgadmin-config", which can be overridden 
by setting the environment variable "HGADMIN_CONFREPO" or using the "--confdir" option.
The "-D" option enables the (rather verbose) debugging output.
""" 
    print(x.format(n=name))

config = None
configDir = None
confError = False
_DEBUG = False
LOGFILE = "/var/log/hgadmin/hgadmin.log"

def main():
    """main function"""
    global config
    global configDir
    global _DEBUG
    logging.basicConfig(stream=sys.stderr, level=logging.INFO, format='%(levelname)s: %(message)s')
    try:
        logging.getLogger().addHandler(logging.handlers.RotatingFileHandler(LOGFILE, maxBytes=100000, backupCount=10))
    except IOError as e:
        warn('unable to open log file ' + repr(LOGFILE))
    x = BASEDIR
    x = os.getenv("HGADMIN_CONFREPO", x)
    foundArg = True
    while foundArg:
        foundArg = False
        if len(sys.argv) >= 3 and sys.argv[1] == "--confdir":
            x = sys.argv[2]
            del sys.argv[2]
            del sys.argv[1]
            foundArg = True
            continue
        if len(sys.argv) >= 2 and sys.argv[1] == "-D":
            _DEBUG = True
            logging.getLogger().setLevel(logging.DEBUG)
            foundArg = True
            del sys.argv[1]
            continue
        if len(sys.argv) >= 2 and sys.argv[1] == "-q":
            logging.getLogger().setLevel(logging.WARN)
            foundArg = True
            del sys.argv[1]
            continue
    configDir = os.path.abspath(os.path.expanduser(x))
    config = parse_config(configDir)
    debug("config: "+ repr(config))
    if len(sys.argv) == 4 and sys.argv[1] == "maybe_create_repo":
        gen_repo(sys.argv[2], sys.argv[3])
        exit(0)
    elif len(sys.argv) == 3 and sys.argv[1] == "create_repo":
        path_ok, sane_path = sanitize_path(sys.argv[2], create_needed = True)
        if not path_ok:
            fail("invalid path: " + repr(sys.argv[2]) + " " + repr(sane_path))
        gen_repo_nocheck(sane_path)
        exit(0)
    elif len(sys.argv) == 3 and sys.argv[1] == "make_repo_managed":
        path_ok, sane_path = sanitize_path(sys.argv[2], create_needed = False)
        if not path_ok:
            fail("invalid path: " + repr(sys.argv[2]) + " " + repr(sane_path))
        make_repo_managed(sane_path, save_hgrc = True)
        exit(0)
    elif len(sys.argv) == 2 and sys.argv[1] == "updateauth":
        update_auth()
        exit(0)
    elif len(sys.argv) == 2 and sys.argv[1] == "verify":
        if confError:
            exit(1)
        exit(0)
    elif len(sys.argv) == 5 and sys.argv[1] == "accesscheck":
        accesstype = sys.argv[2]
        user = sys.argv[3]
        unsan_path = sys.argv[4]
        flag, p = sanitize_path(unsan_path, create_needed = False)
        if flag:
            repopatlist = find_matching_repopatterns(p)
            print(user in gen_accesssets(repopatlist)[accesstype])
            exit(0)  
        else:
            print(False)
            exit(1)
    elif len(sys.argv) == 3 and sys.argv[1] == "getpattern":
        flag, p = sanitize_path(sys.argv[2], create_needed = False)
        if flag:
            print(repr(find_matching_repopatterns(p)))
            exit(0)  
        else:
            print(False)
            exit(1)  
    elif len(sys.argv) == 2 and sys.argv[1] == "listusers":
        for u in sorted(config.userlist):
            print(u)
        exit(0)
    elif len(sys.argv) == 2 and sys.argv[1] == "listgroups":
        for g in sorted(config.groupdict):
            print(g)
        exit(0)
    elif len(sys.argv) == 3 and sys.argv[1] == "listusersingroup":
        if not sys.argv[2] in config.groupdict:
            fail("unknown group")
        for u in sorted(config.groupdict[sys.argv[2]]):
            print(u)
        exit(0)
    elif len(sys.argv) == 2 and sys.argv[1] == "showunmanagedrepos":
        for y in sorted(list_all_repos(list_unmanaged=True)):
            print(y)
        exit(0)
    elif len(sys.argv) == 2 and sys.argv[1] == "showrepos":
        for y in sorted(list_all_repos(list_unmanaged=False)):
            print(y)
        exit(0)
    else:
        usage(sys.argv[0])
        exit(1)

def fail(msg):
    """helper function in case of catastrophic error"""
    logging.error(msg)
    sys.stderr.write("failure: " + msg + "\n")
    exit(1)


def debug(msg):
    """helper function for debugging"""
    logging.debug(msg)

def warn(msg):
    """helper function for important warnings"""
    logging.warning(msg)

def info(msg):
    """helper function for somewhat important information"""
    logging.info(msg)

def closefd(fd):
    """helper function to reliably close and flush a file"""
    fd.flush()
    # if hgadmin is too slow (on linux), go complain to theodore t'so 
    # and comment out this line.
    os.fdatasync(fd.fileno())
    # if you use a _recent_ kernel, and ext3/4 with data=ordered or data=journal
    # this fdatasync "should" be unnecessary anyway, because we do a rename on all
    # files after having written them...
    fd.close()

def make_repo_managed(sane_path, save_hgrc = False):
    """converts a unmanaged repo to a managed repository"""
    if save_hgrc:
        try:
            os.rename(sane_path+'/.hg/hgrc', sane_path+'/.hg/hgrc_prefix')
        except Exception as e:
            pass
    elif not os.access(sane_path+'/.hg/hgrc_prefix', os.F_OK):
        x = open(sane_path+'/.hg/hgrc_prefix', "w")
        x.write("\n# hgrc_prefix is the repository - local static configuration file\n")
        x.write("# here, you can put configuration stuff (like email notification etc.\n") 
        x.write("# that you do not want overwritten automatically\n")
        x.write("# Note that you must not include a [web] section in here!\n\n")
        x.close()
    gen_hgrc(sane_path)
    x = open(sane_path+'/.hg/ADMINISTRATED_BY_HGADMIN', "w")
    x.write("foo")
    closefd(x)

def gen_repo_nocheck(sane_path):
    """creates a managed repository, without any security checks"""
    dispatch.dispatch(request(['init', sane_path]))
    make_repo_managed(sane_path)
    info("created repo at " + repr(sane_path))
    

def gen_repo(user, unsanitized_repopath):
    """creates a repository, if user is allowed to do"""
    path_ok, sane_path = sanitize_path(unsanitized_repopath, create_needed = True)
    if not path_ok:
        fail("invalid path")
    if not user in config.userlist:
        fail("unknown user")
    repopatlist = find_matching_repopatterns(sane_path)
    if not user in gen_accesssets(repopatlist)["create"]:
        fail("access denied")
    gen_repo_nocheck(sane_path)

def update_auth():
    """updates authentication information for all managed repositories, authorized_keys and htpasswd."""
    repolist = list_all_repos()
    for repo in repolist:
        gen_hgrc(repo)
    gen_authkeys()
    update_htpasswd()
    info("updated access and authentication, config repo at " + os.getenv("HG_NODE", "unknown"))

def list_all_repos(list_unmanaged = False):
    """returns a list of all (un)managed repositories in the repo path"""
    repolist = []
    f = config.paths['repopath']
    for root, dirs, files in os.walk(f, topdown=True):
        if is_managed_repo(root, isAbs=True):
            if not list_unmanaged:
                repolist.append(root)
        elif is_unmanaged_repo(root, isAbs=True):
            if list_unmanaged:
                repolist.append(root)
        if '.hg' in dirs: 
            dirs.remove('.hg')
    debug("all repos: " + repr(repolist))
    return repolist

def is_managed_repo(repo, isAbs=False):
    """given a path to a repo, returns True iff said repository is managed by hgadmin"""
    if isAbs:
        repopath = repo
    else:
        root = config.paths['repopath']
        repopath = root + '/' + repo
    x = os.access(repopath + '/.hg/ADMINISTRATED_BY_HGADMIN', os.F_OK)
    debug("is_managed_repopath" + repr(repopath) + " : " + repr(x))
    return x

def is_unmanaged_repo(repo, isAbs=False):
    """given a path to a repo, returns True iff said repository is not managed by hgadmin"""
    if isAbs:
        repopath = repo
    else:
        root = config.paths['repopath']
        repopath = root + '/' + repo
    x = os.access(repopath + '/.hg/00changelog.i', os.F_OK)
    debug("is_unmanaged_repo" + repr(repopath) + " : " + repr(x))
    return x
    

class confobj: # object to save configuration settings
    """singleton object to save configuration settings

    important members:
      userlist: list of users
      groupdict: dictionary; key is group name, value is list of users in group
      paths:  dictionary of paths to relevant files.
        Important Paths:
           paths['hg-ssh']           path to 'hg-ssh' wrapper script
           Paths['repopath']         path to directory with the managed repositories
           paths['htpasswdpath']     path to htpasswd file supposed to be updated
           paths['sshauthkeyspath']  path to authorized_keys file supposed to be updated
           paths['confdir']          path to configuration directory
           paths['globalhgrc']       path to hgrc file for all managed repos
           paths['sshkeydir']        path to dir containing all users' ssh keys 
           paths['managedhtpwd']     path to the master htpasswd file
      accessdict: multi-level dictionary containing access information.
        Example: 
           user  "u1" is granted "read"-access to anything matching pattern "/foo/**" iff:
             "u1" in accessdict["/foo**"]["user"]["read"]
           group "gq" is granted "write"-access to anything matching pattern "/bar/*" iff:
             "gq" in accessdict["/bar/*"]["group"]["write"]
    """
    def __init__(self):
        self.userlist = None
        self.groupdict = None
        self.accessdict = None
        self.paths = None
    def __repr__(self):
        return "config:\n" \
            + "  userlist: "   + repr(self.userlist) + "\n" \
            + "  groupdict: "  + repr(self.groupdict) + "\n" \
            + "  accessdict: " + repr(self.accessdict) + "\n" \
            + "  paths: "      + repr(self.paths) + "\n" 


def parse_config(confdir):
    """function to parse configuration and initialize configuration object"""
    global confError

    def _valid_name(name):
        validchars = string.letters + string.digits + '_-+&'
        for c in name:
            if not c in validchars:
                return False
        if len(name) == 0:
            return False
        return True
    
    def _valid_repopattern(pattern):
        if pattern.endswith('/**'):
            pattern = pattern[:-2]
        elif pattern.endswith('/*'):
            pattern = pattern[:-1]
        if (pattern[0] != '/') or pattern.find('/.') != -1:
            return False
        if pattern.find('*') != -1:
            return False
        return True

    def _splitoption(option):
        #debug("option: " + repr(option))
        option_woc = re.sub(r"#[^\n]*", "", option)
        #debug("option: " + repr(option_woc))
        option_notc = option_woc.rstrip().rstrip(',')
        #debug("option: " + repr(option_notc))
        option_split =  option_notc.split(',') 
        #debug("option: " + repr(option_split))
        option_retlist =  [ x.strip() for x in option_split if x.strip() != '' ]
        #debug("option: " + repr(option_retlist))
        return sorted(option_retlist)

    confFile = os.path.join(confdir, 'config')
    accessFile = os.path.join(confdir, 'access')
    try:
        accessfd = open(accessFile)
        conffd = open(confFile)
        configContent = ConfigParser.RawConfigParser()
        configContent.readfp(conffd)
        accessContent = ConfigParser.RawConfigParser()
        accessContent.readfp(accessfd)
        conffd.close()
        accessfd.close()
    except IOError as e:
        usage(sys.argv[0])
        fail("unable to read configuration files")
    paths = {}
    groupdict = {}
    # do not set defaults...
    # paths['hg-ssh']          = os.path.join(confdir, 'hg-ssh')
    # paths['repopath']        = os.path.expanduser('~/repos')
    # paths['htpasswdpath']    = os.path.expanduser('~/repos/htpasswd')
    # paths['sshauthkeyspath'] = os.path.expanduser('~/.ssh/authorized_keys')
    for option in ['hg-ssh', 'repopath', 'htpasswdpath', 'sshauthkeyspath']:
        if configContent.has_option('paths', option):
            paths[option] = os.path.expanduser(configContent.get('paths', option))
    if not 'repopath' in paths:
        usage(sys.argv[0])
        fail("configuration variable 'repopath' not set")
    paths['confdir']         = confdir
    paths['globalhgrc']      = os.path.join(confdir, 'hgrc')
    paths['sshkeydir']       = os.path.join(confdir, 'keys')
    paths['managedhtpwd']    = os.path.join(confdir, 'htpasswd')
    for option in ['additionalusersfile', 'additionalgroupsfile']:
        if configContent.has_option('paths', option):
            x = os.path.expanduser(configContent.get('paths', option))
            paths[option] = os.path.join(confdir, x)
    for group in configContent.options('groups'):
        groupdict[group] = _splitoption(configContent.get('groups', group)) 
    userlist = _splitoption(configContent.get('users', 'users'))
    if 'additionalusersfile' in paths:
        x = None
        try:
            x = open(paths['additionalusersfile'], "r").read()
            addul      = [ y.strip() for y in x.rstrip().rstrip(',').split(',') ]
            validaddul = [ y for y in addul if _valid_name(y) ]
            if len(validaddul) == len(addul):
                debug("adding users: " + repr(addul))
                userlist += addul
            else:
                confError = True
                warn("addtionalusersfile contains invalid users, ignoring it")
        except Exception as e:
            confError = True
            warn("could not read addtionalusersfile: " + repr(e))
    if 'additionalgroupsfile' in paths:
        # print("auf")
        try:
            tmpgd = {}
            allvalid = True
            fd = open(paths['additionalgroupsfile'], "r")
            for line in fd.readlines():
                if line.strip() == '':
                    continue # ignore lines with only whitespace
                spline = line.split('=')
                if len(spline) != 2:
                    confError = True
                    warn("addtionalgroupsfile contains invalid entry, ignoring it")
                    continue
                addgroupname = spline[0].strip()
                if not _valid_name(addgroupname):
                    confError = True
                    warn("addtionalgroupsfile contains invalid group %s, ignoring it" % addgroupname)
                    continue
                adduserlist      = [ u.strip() for u in spline[1].rstrip().rstrip(',').split(',') ]  
                validadduserlist = [ u for u in adduserlist if _valid_name(u) ]
                debug("aul: " + repr(adduserlist) + " " + repr(validadduserlist))
                if len(validadduserlist) != len(adduserlist) and spline[1].strip() != '':
                    confError = True
                    warn("addtionalgroupsfile group %s contains invalid users, ignoring group" % addgroupname)
                    continue
                if addgroupname in tmpgd:
                    confError = True
                    warn("addtionalusersfile contains group %s twice, ignoring second occurrence" % addgroupname)
                    continue
                tmpgd[addgroupname] = validadduserlist
            debug("adding groups: " + repr(tmpgd))
            for g in tmpgd:
                if g in groupdict:
                    confError = True
                    warn("addtionalusersfile contains already defined group %s, ignoring group" % g)
                    continue
                groupdict[g] = tmpgd[g]
        except Exception as e:
            confError = True
            warn("could not read addtionalgroupsfile: " + repr(e))
    accessdict = {}
    for path in accessContent.sections():
        accessdict.setdefault(path, {})
        for prefix in ['user', 'group']:
            accessdict[path].setdefault(prefix, {})
            for accesstype in ["read", "write", "create", "deny"]:
                accessdict[path][prefix].setdefault(accesstype, [])
        for userorgroup, accesstype in accessContent.items(path):
            if userorgroup[0] == '@':
                prefix = 'group'
                realname = userorgroup[1:]
            else:
                prefix = 'user'
                realname = userorgroup
            ats = accesstype.strip()
            if ats == 'r':
                accessdict[path][prefix]["read"].append(realname)
            elif ats == 'rw':
                accessdict[path][prefix]["write"].append(realname)
                accessdict[path][prefix]["read"].append(realname)
            elif ats == 'rwC':
                accessdict[path][prefix]["create"].append(realname)
                accessdict[path][prefix]["write"].append(realname)
                accessdict[path][prefix]["read"].append(realname)
            elif ats == '' or ats == 'deny':
                # side effect: user is mentioned in this pattern
                accessdict[path][prefix]["deny"].append(realname)
            else:
                warn(("access file section [%s] at %s: invalid setting, " \
                          + "defaulting to DENY") % (path, userorgroup))              
                accessdict[path][prefix]["deny"].append(realname)

    # now some sanity checks:
    for u in userlist:
        if not _valid_name(u):
            warn("User %s has invalid name" % u)
            confError = True
            userlist.remove(u)
    todelete = set()
    for g in groupdict:
        if not _valid_name(g):
            warn("Group %s has invalid name" % g)
            confError = True
            todelete.add(g)
    for g in todelete: del groupdict[g]
    for g in groupdict:
        for u in groupdict[g]:
            if not u in userlist:
                warn("Group %s refers to undefined user %s" %(g, u))
                confError = True
                groupdict[g].remove(u)
    todelete = []
    for pattern in accessdict:
        if not _valid_repopattern(pattern):
            warn('repo pattern %s is invalid' % pattern)
            confError = True
            todelete.append(pattern)
            continue
        for ug in accessdict[pattern]:
            for accesstype in accessdict[pattern][ug]:
                for userorgroup in accessdict[pattern][ug][accesstype]:
                    # debug("debug_foo:" +" "+ pattern + ' ' + userorgroup +' '+ ug)
                    if ug == 'user' and not userorgroup in userlist:
                        confError = True
                        warn("repo access to %s refers to undefined user %s" \
                                 % (pattern, userorgroup))
                        accessdict[pattern][ug][accesstype].remove(userorgroup)
                    if ug == 'group' and not userorgroup in groupdict:
                        confError = True
                        warn("repo access to %s refers to undefined group %s" \
                                 % (pattern, userorgroup))
                        accessdict[pattern][ug][accesstype].remove(userorgroup)
    for t in todelete:
        del accessdict[t]
    debug("flattening groups")
    for pattern in accessdict:
        rset = set(accessdict[pattern]["user"]["read"])
        wset = set(accessdict[pattern]["user"]["write"])
        dset = set(accessdict[pattern]["user"]["deny"])
        cset = set(accessdict[pattern]["user"]["create"])
        for group in accessdict[pattern]["group"]["read"]:
            rset.update(groupdict[group])
        for group in accessdict[pattern]["group"]["write"]:
            wset.update(groupdict[group])
        for group in accessdict[pattern]["group"]["create"]:
            cset.update(groupdict[group])
        for group in accessdict[pattern]["group"]["deny"]:
            dset.update(groupdict[group])
        accessdict[pattern]["read"]   = frozenset(rset)
        accessdict[pattern]["write"]  = frozenset(wset)
        accessdict[pattern]["create"] = frozenset(cset)
        accessdict[pattern]["deny"]   = frozenset(dset)
    retval = confobj()
    retval.userlist = userlist
    retval.groupdict = groupdict
    retval.accessdict = accessdict
    retval.paths = paths
    return retval

def gentmpsuffix():
    return "_tmp-" + str(os.getpid())

def genbaksuffix():
    return "_bak-" + str(os.getpid())

def replacefile(targetpath, newsuffix):
    """helper function to atomically replace a file while keeping a backup"""
    backupsuffix = genbaksuffix()
    b = targetpath + backupsuffix
    n = targetpath + newsuffix
    targetpresent = True
    try:
        os.remove(b)
    except Exception as e:
        pass
    try:
        os.link(targetpath, b)
    except Exception as e:
        if os.access(targetpath, os.F_OK):
            warn("backing up %s didn't work" % targetpath)
        else:
            targetpresent = False
    try:
        os.rename(n, targetpath)
    except Exception as e:
        os.remove(n)
        raise e
    try:
        os.remove(b)
    except:
        if targetpresent:
            warn("removing backupfile %s didn't work" % b)

def gen_hgrc(repo):
    """creates a hgrc file for a managed repository, with web access information"""
    globalhgrcprefix = config.paths['globalhgrc']
    debug("gen_hgrc: " + repr(repo))
    tmpsuff = gentmpsuffix()
    tgtpath = repo +"/.hg/hgrc"
    tmppath = tgtpath + tmpsuff
    tmpfile = open(tmppath, "w")
    if os.access(globalhgrcprefix, os.R_OK):
        tmpfile.write("\n%include " + globalhgrcprefix)
    if os.access(repo+"/.hg/hgrc_prefix", os.R_OK):
        tmpfile.write("\n%include " + repo+"/.hg/hgrc_prefix")
    tmpfile.write("\n\n[web]\n")
    tmpfile.write("%unset deny_read\n")
    tmpfile.write("%unset deny_push\n")
    tmpfile.write("%unset allow_read\n")
    tmpfile.write("%unset allow_push\n")
    readlist = set()
    writelist = set()
    repopatlist = find_matching_repopatterns(repo)
    repoaccessdict = gen_accesssets(repopatlist)
    readlist = sorted(repoaccessdict["read"].union(repoaccessdict["write"]))
    writelist = sorted(repoaccessdict["write"])
    debug("gen_hgrc: readlist " + repr(readlist))
    debug("gen_hgrc: writelist " + repr(writelist))
    if len(readlist) == 0: 
        tmpfile.write("deny_read = *\n")
    else:
        tmpfile.write("allow_read = ")
        sep = ''
        for user in readlist:
            tmpfile.write(sep + user)
            sep = ', '
        tmpfile.write("\n")
    if len(writelist) == 0:
        tmpfile.write("deny_push = *\n")
    else:
        tmpfile.write("allow_push = ")
        sep = ''
        for user in writelist:
            tmpfile.write(sep + user)
            sep = ', '
        tmpfile.write("\n")
    closefd(tmpfile)
    replacefile(tgtpath, tmpsuff)

def valid_sshkey(x):
    """helper function to determine whether a string is a ssh key"""
    try:
        xs = x.split()
        if len(xs) != 3:
            return False
        keytype, keystring, comment = xs
        keydata = base64.decodestring(key_string)
        str_len = struct.unpack('>I', data[:4])[0]
        return keydata[4:4+str_len] == keytype
    except Exception as e:
        return False

def fetchkey(keyfile):
    """helper function to fetch all ssh keys from a file"""
    try:
        x = subprocess.Popen(["ssh-keygen", "-i", "-f", keyfile], 
                             stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        key = x.stdout.read()
        if x.returncode == 0:
            return [key]
    except subprocess.CalledProcessError as e:
        pass
    keylist = None
    try:
        keylist =  [ x.strip() for x in open(keyfile).readlines() ]
        for l in keylist:
            if not valid_sshkey(l):
                warning("keyfile " + repr(keyfile) \
                            + " contains stuff that does not seem like a" \
                            + " ssh key, ignoring this file")
                return None
    except Exception as e:
        # raise e
        pass
    return keylist

def gen_authkeys():
    """creates authorized_keys file from authorized_keys_const and keys in configuration directory"""
    if not ('sshauthkeyspath' in config.paths and 'hg-ssh' in config.paths):
        info("required configuration settings for authkeyfile " \
                 + "generation missing; skipping generation")
        return
    userlist = config.userlist
    keydir = config.paths['sshkeydir']
    authkeypath = config.paths['sshauthkeyspath']
    tmpsuff = gentmpsuffix()
    tmppath = authkeypath + tmpsuff
    predefpath = authkeypath +"_const"
    os.umask(077)
    tmpfile = open(tmppath, "w")
    try: 
        predef = open(predefpath, "r")
        x = os.fstat(predef.fileno())
        # read predef file only if not writeable by others
        if x.st_mode & (stat.S_IWOTH | stat.S_IWGRP) == 0:
            tmpfile.write(predef.read())
        predef.close()
    except IOError as e:
        pass
    for user in userlist:
        l = []
        try:
            l = os.listdir(keydir + '/' + user)
        except OSError as e:
            continue
        debug("gen_authkeys: for user " + user + " using keyfiles " + repr(l))
        for keyfile in l:
            p = keydir + '/' + user + '/' + keyfile
            keylist = fetchkey(p)
            if keylist == None:
                continue
            for key in keylist:
                tmpfile.write('no-pty,no-port-forwarding,no-X11-forwarding,' \
                                  + 'no-agent-forwarding,command=')
                tmpfile.write('"' +config.paths['hg-ssh'] +' ' \
                                  + config.paths['repopath'] + ' '+ user + ' ' \
                                  + configDir + ' " ' + key + '\n')
    closefd(tmpfile)
    
    replacefile(authkeypath, tmpsuff)

def update_htpasswd():
    """replaces system htpasswd file with htpasswd file from configuration directory"""
    if not 'htpasswdpath' in config.paths:
        info("config setting 'htpasswdpath' missing; skipping update of htpasswd file")
        return
    tochange = config.paths['htpasswdpath']
    newfile = config.paths['managedhtpwd']
    if os.path.exists(newfile):
        os.umask(033)
        tmpsuff = gentmpsuffix()
        x = open(tochange+tmpsuff, "w")
        x.write(open(newfile, "r").read())
        closefd(x)
        replacefile(tochange, tmpsuff)



def sanitize_path(unsanitized_path, create_needed):
    """This function will try sanitize unsanitized_path and return the sanitized version.

    Returns: (b, p) where b is True or False, indicating whether
    sanitation was successfull and p is the sanitized path (or '').

    If create_needed is True, this function will also fail if
    unsanitized_path already exists.  Otherwise, this function will
    also fail if unsanitized_path does not exist.
    """
    if os.sep != '/':
        fail("incompatible operating system!")
    debug("sanitizing path " + repr(unsanitized_path))
    # make root nice
    root = os.path.abspath(config.paths['repopath']).rstrip('/')
    root = os.path.realpath(root)

    # unsan_path_abs shall be a nice version of the interesting path.
    # unsanitized_path might start with root - if not, prepend it.
    if not unsanitized_path.startswith(root):
        unsan_path_abs = os.path.abspath(root + '/' + unsanitized_path).rstrip('/')
    else:
        unsan_path_abs = os.path.abspath(unsanitized_path).rstrip('/')
        
    if unsan_path_abs.find('/.') != -1:
        return (False, '')

    if not create_needed:
        # now, the path must already exist and point to a 
        # nice location. simply check for that
        # first, get the real path (without symlinks)
        san_path_abs = os.path.realpath(unsan_path_abs).rstrip('/')

        dd={'root': root, 'unsan_path_abs': unsan_path_abs,'san_path_abs': san_path_abs}
        debug("saninfo: " + repr(dd))

        # now, check whether it exists and is a directory
        if not( os.path.exists(san_path_abs) and os.path.isdir(san_path_abs) 
                and san_path_abs.startswith(root) ):
            return (False, '')
        return (True, san_path_abs)

    # exist should exist, tocreate must not exist
    exist, tocreate = os.path.split(unsan_path_abs)

    # we want to ignore symlinks - realpath does that
    real_exist = os.path.realpath(exist).rstrip('/')

    debugdict = {'root': root, 'unsan_path_abs': unsan_path_abs,
                 'exist': exist, 'tocreate': tocreate, 'real_exist' : real_exist}
    debug("saninfo: " + repr(debugdict))

    # sanity checks for tocreate
    if ( tocreate == '' or tocreate[0] == '.' 
         or '"' in tocreate or '/' in tocreate ) :
        return (False, '')

    # sanity checks for real_exist
    if not( os.path.exists(real_exist) and os.path.isdir(real_exist) 
            and real_exist.startswith(root) ):
        return (False, '')

    # finally, the sanitized path
    whole_new = real_exist + '/' + tocreate

    # whole_new might exist (even as broken symlink) - check for that
    if os.path.lexists(whole_new):
        return (False, '')
    return (True, whole_new)
    
def find_matching_repopatterns(path):
    """ returns a list of repopatterns that match path, in order of match exactness """
    def _patprefix(pat):
        if pat.endswith('/**'):
            return pat[:-3]
        if pat.endswith('/*'):
            return pat[:-2]
        return pat
        
    def _cmpbylen(a, b):
        ppa = _patprefix(a)
        ppb = _patprefix(b)
        if ppa == ppb:
            return len(a)-len(b)
        return len(ppb)-len(ppa)
    
    def _ispathprefix(path, prefix):
        if not path.startswith(prefix):
            return False
        if len(path) == len(prefix):
            return True
        return '/' == path[len(prefix)]

    def _match_repopat_to_path(repopat, path):
        # debug("matching repopat " + repr(repopat) + " to path " + repr(path))
        if repopat.endswith('/**'):
            prefix = repopat[:-3]
            return _ispathprefix(path, prefix)
        if repopat.endswith('/*'):
            prefix = repopat[:-2]
            if not _ispathprefix(path, prefix):
                return False
            if path == prefix:
                return True
            if len(prefix) + 2 > len(path):
                return False
            if path[len(prefix)] != '/': 
                return False
            pathsuffix = path[len(prefix)+1:]
            if pathsuffix == '' or '/' in pathsuffix:
                return False
            return True
        return repopat == path

    repopatlist = list(config.accessdict.keys())
    # debug("find_matching_repopatterns: repopatlist: " +
    # repr(repopatlist) + ' path: ' + repr(path))
    retlist = []
    for repopat in repopatlist:
        extended_repopat = os.path.normpath(config.paths['repopath'] + '/' + repopat).rstrip('/')
        # extended_repopat and path both have no redundant or trailing slashes
        if _match_repopat_to_path(extended_repopat, path):
            retlist.append(repopat)
    retlist.sort(cmp=_cmpbylen)
    debug("find_matching_repopatterns: path " + repr(path) + " found " + repr(retlist))
    return retlist

    

def gen_accesssets(patterns):
    rset = set()
    wset = set()
    cset = set()
    dset = set()
    unknown = set(config.userlist)
    for x in patterns:
        p = config.accessdict[x]
        rset.update(p["read"  ].intersection(unknown))
        wset.update(p["write" ].intersection(unknown))
        cset.update(p["create"].intersection(unknown))
        dset.update(p["deny"  ].intersection(unknown))
        unknown.difference_update(p["read"], p["write"], p["create"], p["deny"])
        debug("accessets: pattern: " + x + " sets: " \
                  + repr({"read": rset, "write": wset, "create": cset, 
                          "deny": dset, "unknown" : unknown}))
        if len(unknown) == 0:
            break
    dset.update(unknown)
    return {"read": rset, "write": wset, "create": cset, "deny": dset}

if __name__ == "__main__":
    main()
  
